apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: fastapi-latency-autoscaler
  namespace: default
spec:
  scaleTargetRef:
    name: model # update to your actual deployment name
  minReplicaCount: 1
  maxReplicaCount: 5
  pollingInterval: 30 # seconds
  # KEDA checks the scaling triggers every 30 seconds to determine whether scaling is needed.
  cooldownPeriod: 300 # seconds before scaling down
  # After scaling down, KEDA waits 5 minutes before another scale-down can occur, 
  # preventing frequent scale-downs that could destabilize workloads
  triggers:
    - type: prometheus
      metadata:
        serverAddress: http://prom-kube-prometheus-stack-prometheus.monitoring.svc:9090
        metricName: fastapi_latency_p95
        query: |
          histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[1m])) by (le))
        threshold: "0.5"
    - type: prometheus
      metadata:
        serverAddress: http://prom-kube-prometheus-stack-prometheus.monitoring.svc:9090
        metricName: request_rate
        query: sum(rate(http_requests_total[1m]))
        threshold: "1000"